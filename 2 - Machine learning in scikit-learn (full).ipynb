{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning Fundamentals<br />\n",
    "<h2><p style=\"color:darkred\">2 - Machine learning with scikit-learn</p></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Code repeatability\n",
    "In scientific computing, controlling the state of the PRNG is essential to obtain code which is easily <em>repeatable</em>, and hence easy to debug and/or reproduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22199317108973948\n"
     ]
    }
   ],
   "source": [
    "# The following snippet can be used to initialize the PRNG \n",
    "# with a specific seed:\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(5)\n",
    "np.random.seed(5)\n",
    "print(np.random.rand())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"Images/supervised-workflow-machine-learning.png\">\n",
    "<a href=\"http://blog.bidmotion.com/2016/06/23/good-morning-have-you-used-machine-learning/\">Image source</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>Let us download the sample data: <a href=\"https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\">\n",
    "Default of credit card clients Data Set</a></p>\n",
    "<br />\n",
    "<div class=\"alert alert-success\">\n",
    "<p>Take a look at the <a href=\"https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset\">Kaggle challenge</a> to find some further ideas on the dataset!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We want to understand the default probability of a client (Yes = 1, No = 0), given:\n",
    "\n",
    "<ol>\n",
    "<li><strong>X1</strong>: Amount of the given credit (NT dollars): it includes both the individual consumer credit and his/her family (supplementary) credit.</li>\n",
    "<li><strong>X2</strong>: Gender (1 = male; 2 = female). \n",
    "<li><strong>X3</strong>: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others, 5 = unknown, 6 = unknown).</li>\n",
    "<li><strong>X4</strong>: Marital status (1 = married; 2 = single; 3 = others).</li>\n",
    "<li><strong>X5</strong>: Age (year).</li>\n",
    "<li><strong>X6 - X11</strong>: History of past payment (X6 = repayment status in September, 2005; X7 = the repayment status in August, 2005, ...) The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. </li>\n",
    "<li><strong>X12-X17</strong>: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. </li>\n",
    "<li><strong>X18-X23</strong>: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 1 - Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type       Data/Info\n",
      "-------------------------------\n",
      "X          ndarray    30000x23: 690000 elems, type `float64`, 5520000 bytes (5.2642822265625 Mb)\n",
      "data       dict       n=5\n",
      "np         module     <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "random     module     <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "scipy      module     <module 'scipy' from 'C:\\<...>ges\\\\scipy\\\\__init__.py'>\n",
      "y          ndarray    30000x1: 30000 elems, type `float64`, 240000 bytes (234.375 kb)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat('./Data/credit_card_data.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Play with X / y to understand the content!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can describe the dataset using the <code>describe</code> function from <code>scipy.stats</code> and Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>167484.322667</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>1.853133</td>\n",
       "      <td>1.551867</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>-0.133767</td>\n",
       "      <td>-0.166200</td>\n",
       "      <td>-0.220667</td>\n",
       "      <td>-0.266200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.701315e+04</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>129747.661567</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.790349</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>1.196868</td>\n",
       "      <td>1.169139</td>\n",
       "      <td>1.133187</td>\n",
       "      <td>...</td>\n",
       "      <td>6.934939e+04</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.572640e+05</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666250e+03</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.008850e+04</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.016475e+04</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.664089e+06</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0             1             2             3             4   \\\n",
       "count    30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean    167484.322667      1.603733      1.853133      1.551867     35.485500   \n",
       "std     129747.661567      0.489129      0.790349      0.521970      9.217904   \n",
       "min      10000.000000      1.000000      0.000000      0.000000     21.000000   \n",
       "25%      50000.000000      1.000000      1.000000      1.000000     28.000000   \n",
       "50%     140000.000000      2.000000      2.000000      2.000000     34.000000   \n",
       "75%     240000.000000      2.000000      2.000000      2.000000     41.000000   \n",
       "max    1000000.000000      2.000000      6.000000      3.000000     79.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean      -0.016700     -0.133767     -0.166200     -0.220667     -0.266200   \n",
       "std        1.123802      1.197186      1.196868      1.169139      1.133187   \n",
       "min       -2.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        8.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "           ...                  13             14             15  \\\n",
       "count      ...        3.000000e+04   30000.000000   30000.000000   \n",
       "mean       ...        4.701315e+04   43262.948967   40311.400967   \n",
       "std        ...        6.934939e+04   64332.856134   60797.155770   \n",
       "min        ...       -1.572640e+05 -170000.000000  -81334.000000   \n",
       "25%        ...        2.666250e+03    2326.750000    1763.000000   \n",
       "50%        ...        2.008850e+04   19052.000000   18104.500000   \n",
       "75%        ...        6.016475e+04   54506.000000   50190.500000   \n",
       "max        ...        1.664089e+06  891586.000000  927171.000000   \n",
       "\n",
       "                  16             17            18            19  \\\n",
       "count   30000.000000   30000.000000  3.000000e+04   30000.00000   \n",
       "mean    38871.760400    5663.580500  5.921163e+03    5225.68150   \n",
       "std     59554.107537   16563.280354  2.304087e+04   17606.96147   \n",
       "min   -339603.000000       0.000000  0.000000e+00       0.00000   \n",
       "25%      1256.000000    1000.000000  8.330000e+02     390.00000   \n",
       "50%     17071.000000    2100.000000  2.009000e+03    1800.00000   \n",
       "75%     49198.250000    5006.000000  5.000000e+03    4505.00000   \n",
       "max    961664.000000  873552.000000  1.684259e+06  896040.00000   \n",
       "\n",
       "                  20             21             22  \n",
       "count   30000.000000   30000.000000   30000.000000  \n",
       "mean     4826.076867    4799.387633    5215.502567  \n",
       "std     15666.159744   15278.305679   17777.465775  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%       296.000000     252.500000     117.750000  \n",
       "50%      1500.000000    1500.000000    1500.000000  \n",
       "75%      4013.250000    4031.500000    4000.000000  \n",
       "max    621000.000000  426529.000000  528666.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import pandas as pd\n",
    "pd.DataFrame(X).describe()\n",
    "pd.DataFrame(y).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+QVeWd5/H3Z/BHfmkARYfwYxoNcaLWBLEXmXUnZTQg\nYjaYLd3F2YqsoYb8wEkyye4Ik60xo0MVZpK4sWLMovaIU0akNK6UoqTHmHVTJUhjEEE0tMhoKwMk\nIDHlxATy3T/Oc/XQfe/t2/Tt2+fe/ryqbt1zvuc5957THM73nud5znMUEZiZmRXNHwz3BpiZmZXj\nBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXkBGVmZoXUb4KS9C5JT0l6RtI2SX+X\n4ndKeknS5vSaluKSdLOkbklbJE3PfdYCSTvSa8HQ7ZaZmTW7Y2oo8xZwYUT8WtKxwE8lPZKW/Y+I\nuK9X+UuAqel1HnArcJ6kscB1QDsQwCZJayLiQKUvPvnkk6OtrW1AO2RH2rRp0y8iYtxwb0cR+Hga\nHB9L7/CxNDi1Hkv9JqjIxkL6dZo9Nr2qjY80D7grrbde0mhJ44ELgM6I2A8gqROYA9xT6YPa2tro\n6urqbxOtCkn/MtzbUBQ+ngbHx9I7fCwNTq3HUk1tUJJGSdoM7CVLMhvSomWpGu8mScen2ATgldzq\nPSlWKd77uxZJ6pLUtW/fvlo2z8zMWlBNCSoiDkfENGAiMEPS2cBS4I+BfweMBa5NxVXuI6rEe3/X\niohoj4j2ceNcm2BmNlINqBdfRLwO/ASYExG7I/MW8I/AjFSsB5iUW20i8FqVuJmZWR+19OIbJ2l0\nmn438HHg+dSuhCQBlwFb0yprgKtSb76ZwMGI2A2sA2ZLGiNpDDA7xczMzPqopRffeGClpFFkCW11\nRDwk6ceSxpFV3W0GPpfKrwXmAt3Am8DVABGxX9INwMZU7vpShwkzM7PeaunFtwU4p0z8wgrlA1hc\nYVkH0DHAbTQzsxHII0mYmVkhOUGZWaFJ6pC0V9LWMsv+u6SQdHKaH/BINpLOlfRsWufm1K5uBeAE\nZWZFdyfZTf1HkDQJmAW8nAvnR7JZRDaSDbmRbM4j63F8XeqsRSqzKLden++y4eEEZWaFFhFPAOU6\nVN0E/DVH3k/59kg2EbEeKI1kczFpJJs0vFonMCctOzEinkzt53eR9Uq2AqilF18htS15mF3LLx3u\nzTBram1LHq64rMj/vyR9Eng1Ip7pVSM30JFsJqTp3vFy37mI7EqLyZMnD3IP+lft3waK/e9TL76C\nMrOmIuk9wNeAvy23uEys2kg2NY1wAx7lZjg4QZlZszkdmAI8I2kX2ag0T0v6QwY+kk1Pmu4dtwJw\ngjKzphIRz0bEKRHRFhFtZElmekT8KwMcySYte0PSzNR77yrgwWHZMevDCcrqrly3YEn35h5uuSuN\njo+kNkn/llv2/dw6Zbv/ShorqTN1F+7M9cayFiTpHuBJ4AxJPZIWVim+FthJNpLNbcAXIBvJBiiN\nZLORI0ey+Txwe1rnReARrBCatpOEFdqdwHfJekQBEBH/pTQt6VvAwVz5F9No+b2Vuv+uJzvxzCE7\neSwBHouI5ZKWpPlry6xvLSAiruxneVtuesAj2UREF3D24LbShoKvoKzuqnQLLg0u/J+p8qDKVK5a\n9995wMo0vRJ3CzZrSU5Q1mh/BuyJiB252BRJP5P0fyX9WYpV6/57amo7IL2fMtQbbWaN5yo+a7Qr\nOfLqaTcwOSJ+Kelc4P9IOosBdP+tptH3rphZ/fgKyhpG0jHAfwLuLcUi4q2I+GWa3kTWSP0hqnf/\n3ZN7Htl4YG+l7/S9K2bNywnKGunjwPMR8XbVXXog5qg0fRrZWGg7++n+uwYoDfa5AHcLNmtJTlBW\nd1W6Bc+nb+eIjwJbJD0D3Ad8robuv8uBWZJ2kA0WunzIdsbMho3boKzuKnULjoj/ViZ2P3B/hfJl\nu/+mKsGLBreVZlZ0voIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIy\nM7NCcoIyM7NC6jdBSXqXpKckPSNpm6S/S/Epkjakp5reK+m4FD8+zXen5W25z1qa4i9IuniodsrM\nzJpfLVdQbwEXRsRHgGnAHEkzgRuBmyJiKnAAKI23thA4EBEfBG5K5ZB0JtlYbGeRPRn1e6VBQs3M\nzHrrN0FF5tdp9tj0CuBCssE94cinmuafdnofcFEajXoesCo9XuElsgFAZ9RlL8zMrOXU1AYlaZSk\nzWTP3ekkG1n69Yg4lIrkn3Y6AXgFIC0/CJyUj5dZJ/9diyR1Serat2/fwPfIzMxaQk0JKiIOR8Q0\nsofGzQA+XK5Yeq/0JNSanpDqB8yZmRkMsBdfRLwO/ASYCYxOT0iFI5922gNMgrefoPp+YH8+XmYd\nMzOzI9TSi2+cpNFp+t1kT0XdDjwOXJ6K5Z9qmn/a6eXAjyMiUnx+6uU3hezJqU/Va0fMzKy11PLA\nwvHAytTj7g+A1RHxkKTngFWS/h74GXBHKn8H8E+SusmunOYDRMQ2SauB54BDwOKIOFzf3TEzs1bR\nb4KKiC3AOWXiOynTCy8ifgNcUeGzlgHLBr6ZZjYSSeoAPgHsjYizU+wfgP8I/Jasw9bVqfkBSUvJ\nbnU5DHwxItal+BzgO8Ao4PaIWJ7iU4BVwFjgaeDTEfHbxu2hVeORJMysyO4ku28yrxM4OyL+BPg5\nsBQq32uZan9uAS4BzgSuTGWh8v2cVgBOUGZWWBHxBFlTQT72o9wtLuvJOlxB5XstZwDdEbEzXR2t\nAual+zMr3c9pBeAEZWbN7DPAI2m60r2WleInUfl+zj58j2bjOUGZWVOS9DWyDld3l0JlilW7B7Om\nezPfXuB7NBuull58ZmaFImkBWeeJi9JtLFD9Xsty8V+Q7udMV1G+N7NgfAVlZk0l9ci7FvhkRLyZ\nW1TpXsuNwNT0BIbjyDpSrEmJrdL9nFYATlBWd5I6JO2VtDUX+7qkVyVtTq+5uWVlH8MiaU6KdUta\nkouXfdSLtR5J9wBPAmdI6pG0EPgucALQmY6l70N2ryVQutfyUdK9lunq6BpgHdkgA6tTWcgS3VfS\nfZsn8c79nFYAruKzoXAn2Unkrl7xmyLim/lAr67BHwD+WdKH0uJbgFlkVTcbJa2JiOd4p2vwqnRy\nWgjcOlQ7Y8MnIq4sE66YRCrdaxkRa4G1ZeJl7+e0YvAVlNVdua7BVbhrsJmV5QRljXSNpC2pCnBM\nirlrsJmV5QRljXIrcDrZU5l3A99KcXcNNrOy3AZlDRERe0rTkm4DHkqz7hpsZmX5CsoaQtL43Oyn\ngFIPP3cNNrOyfAVldZe6Bl8AnCypB7gOuEDSNLLquF3AZ6H6Y1gklboGjwI6enUNLveoFzNrIU5Q\nVnfuGmxm9eAqPjMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQn\nKDMzKyQnKDMzKyQnKDMzK6R+x+KTNIns0d1/CPweWBER35H0deAvgNJT4P4mjZ2GpKVkj+E+DHwx\nItal+BzgO2SDf94eEcvruztmZsXStuThist2Lb+0gVvSfGoZLPYQ8NWIeFrSCcAmSZ1p2U0R8c18\nYUlnkj0a4SzgA8A/S/pQWnwLMIvsGUAbJa2JiOfqsSNmZtZa+k1QEbGb7AmoRMQbkrZT5RHbwDxg\nVUS8BbwkqZt3Rp7uTiNRI2lVKusEZWZmfQyoDUpSG3AOsCGFrpG0RVKHpDEpNgF4JbdaT4pVivf+\njkWSuiR17du3r/diMzMbIWpOUJLeB9wPfDkifgXcCpwOTCO7wvpWqWiZ1aNK/MhAxIqIaI+I9nHj\nxtW6eWZm1mJqemChpGPJktPdEfFDgIjYk1t+G/BQmu0BJuVWnwi8lqYrxc3MzI7Q7xWUJJE9DXV7\nRHw7Fx+fK/YpYGuaXgPMl3S8pCnAVOApYCMwVdIUSceRdaRYU5/dMDOzVlNLFd/5wKeBCyVtTq+5\nwDckPStpC/Ax4K8AImIbsJqs88OjwOKIOBwRh4BrgHXAdmB1KmtmVlFq494raWsuNlZSp6Qd6X1M\nikvSzZK6U/v49Nw6C1L5HZIW5OLnpnNZd1q3XHOEDYNaevH9lPLtR2urrLMMWFYmvrbaemZmZdwJ\nfJfsfsySJcBjEbFc0pI0fy1wCVmtzVTgPLK28vMkjQWuA9rJ2r43pdtcDqQyi4D1ZOenOcAjDdgv\n64dHkjCzQouIJ4D9vcLzgJVpeiVwWS5+V2TWA6NTc8TFQGdE7E9JqROYk5adGBFPRkSQJcHLsEJw\ngjKzZnRqukezdK/mKSk+0NtcJqTp3vE+fAtM4zlBmVkrGehtLjXd/gK+BWY4OEFZ3VVo1P4HSc+n\nhusHJI1O8TZJ/5brgPP93DplG68rNZDbiLKn1JM4ve9N8Uq3uVSLTywTtwJwgrKhcCdZQ3NeJ3B2\nRPwJ8HNgaW7ZixExLb0+l4uXGq9Ljd6lzyw1kE8FHkvzNrKsAUo98RYAD+biV6XefDOBg6kKcB0w\nW9KY9INmNrAuLXtD0sz0A+iq3GfZMHOCsror16gdET9KtxpA1ltqYp8Vc/ppvK7UQG4tSNI9wJPA\nGZJ6JC0ElgOzJO0gG4C69GSEtcBOoBu4DfgCQETsB24gux9zI3B9igF8Hrg9rfMi7sFXGDWNJGFW\nZ58B7s3NT5H0M+BXwP+MiP9H9cbrIxrIJZ1CBZIWkV2FMXny5PrtgTVMRFxZYdFFZcoGsLjC53QA\nHWXiXcDZg9lGGxq+grKGkvQ1ske43J1Cu4HJEXEO8BXgB5JOZACN19W4YdusefkKyhom3b3/CeCi\n9EuX9FiWt9L0JkkvAh+ieuP1Hknj09VTvoHczFqIr6CsIdLTlK8FPhkRb+bi4ySNStOnkXWG2NlP\n43WlBnIzayG+grK6S43aFwAnS+ohG2JmKXA80Jl6i69PPfY+Clwv6RBwGPhcr8brO4F3kzVclxqv\nlwOrU2P5y8AVDdgtM2swJyiruwqN2ndUKHs/2aNcyi0r23gdEb+kTAO5mbUWV/GZmVkhOUGZmVkh\nuYrPRqS2JQ9XXb5r+aUN2hIzq8RXUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhO\nUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkj9JihJkyQ9Lmm7pG2SvpTiYyV1StqR3sekuCTdLKlb0hZJ\n03OftSCV35EeXmdmZlZWLVdQh4CvRsSHgZnAYklnAkuAxyJiKvBYmge4hOyhc1OBRcCtkCU0sucC\nnQfMAK4rJTUzM7Pe+k1QEbE7Ip5O028A24EJwDxgZSq2ErgsTc8D7orMemB0eiz3xUBnROyPiANA\nJzCnrntjZmYtY0BtUJLagHOADcCp6bHcpPdTUrEJwCu51XpSrFLczMysj5oTlKT3kT359MsR8atq\nRcvEokq89/csktQlqWvfvn21bp6ZmbWYmhKUpGPJktPdEfHDFN6Tqu5I73tTvAeYlFt9IvBalfgR\nImJFRLRHRPu4ceP6bEt/z/ExM7PWUEsvPgF3ANsj4tu5RWuAUk+8BcCDufhVqTffTOBgqgJcB8yW\nNCZ1jpidYmZmAybpr1LP4q2S7pH0LklTJG1IPYXvlXRcKnt8mu9Oy9tyn7M0xV+QdPFw7Y/1VcsV\n1PnAp4ELJW1Or7nAcmCWpB3ArDQPsBbYCXQDtwFfAIiI/cANwMb0uj7FzMwGRNIE4ItAe0ScDYwC\n5gM3Ajel3sUHgIVplYXAgYj4IHBTKkfqkTwfOIus09b3JI1q5L5YZf0+8j0ifkr59iOAi8qUD2Bx\nhc/qADoGsoFmZhUcA7xb0u+A9wC7gQuBP0/LVwJfJ7vVZV6aBrgP+G6qHZoHrIqIt4CXJHWT3Qbz\nZIP2warwSBJm1nQi4lXgm8DLZInpILAJeD0iDqVi+Z7Cb/ciTssPAicxgN7F7sDVeE5QVneSOiTt\nlbQ1F6vbyCOSzpX0bFrn5vRL2EaQdPzMA6YAHwDeSzZIQG+lnsKD6l0M/XfgsvpzgrKhcCd9b8Ku\n58gjt6aypfV8w/fI83HgpYjYFxG/A34I/HuygQFKTRf5nsJv9yJOy98P7KfG3sU2PJygrO4i4gmy\n//x5dRl5JC07MSKeTO2dd+U+y0aOl4GZkt6TrqAvAp4DHgcuT2V69y4uXYVfDvw4HT9rgPmpl98U\nsh88TzVoH6wf/XaSMKuTI0YekXS0I49MSNO942VJWkR2tcXkyZMHuQtWFBGxQdJ9wNNk44X+DFgB\nPAyskvT3KXZHWuUO4J9SJ4j9ZD33iIhtklaTJbdDwOKIONzQnbGKnKBsuA20baDmNgPI2g3ITly0\nt7dXLGfNJyKuI6sGzttJViXcu+xvgCsqfM4yYFndN9AGzVV81ij1GnmkJ033jptZi3GCskapy8gj\nadkbkmamtoercp9lZi3EVXxWd5LuAS4ATpbUQ1YNsxxYLWkhWQN3qbplLTCXbOSRN4GrIRt5RFJp\n5BE4cuSRz5P1FHw38Eh6mVmLcYKyuouIKyssqsvIIxHRBZw9mG00s+JzFZ+ZmRWSE5SZmRWSE5SZ\nmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRWSE5SZmRWS\nE5SZmRWSE5SZmRWSE5SZmRVS0yeotiUPD/cmmJnZEOg3QUnqkLRX0tZc7OuSXpW0Ob3m5pYtldQt\n6QVJF+fic1KsW9KS+u+KmZm1klquoO4E5pSJ3xQR09JrLYCkM4H5wFlpne9JGiVpFHALcAlwJnBl\nKtsQvsoyM2s+/T7yPSKekNRW4+fNA1ZFxFvAS5K6gRlpWXdE7ASQtCqVfW7AW2xmZiPCYNqgrpG0\nJVUBjkmxCcAruTI9KVYp3oekRZK6JHXt27dvEJtnZmbN7GgT1K3A6cA0YDfwrRRXmbJRJd43GLEi\nItojon3cuHFHuXlm1uokjZZ0n6TnJW2X9KeSxkrqlLQjvY9JZSXp5tQGvkXS9NznLEjld0haMHx7\nZL0dVYKKiD0RcTgifg/cxjvVeD3ApFzRicBrVeJmZkfrO8CjEfHHwEeA7cAS4LGImAo8luYha/+e\nml6LyH5kI2kscB1wHtl57LpcjZANs6NKUJLG52Y/BZR6+K0B5ks6XtIUsoPhKWAjMFXSFEnHkXWk\nWHP0m21mI5mkE4GPAncARMRvI+J1srbtlanYSuCyND0PuCsy64HR6Tx2MdAZEfsj4gDQSflOYTYM\n+u0kIeke4ALgZEk9ZL82LpA0jayabhfwWYCI2CZpNVnnh0PA4og4nD7nGmAdMAroiIhtdd8bMxsp\nTgP2Af8o6SPAJuBLwKkRsRsgInZLOiWVH3T7uDVeLb34riwTvqNK+WXAsjLxtcDaAW2dtRRJZwD3\n5kKnAX8LjAb+guyEA/A3uVsXlgILgcPAFyNiXYrPIaviGQXcHhHLG7ITVhTHANOBv4yIDZK+wzvV\neeUMun1c0iKy6kEmT548sK21o9L0I0lY84iIF0r3zgHnAm8CD6TFTXNfnRVCD9ATERvS/H1kCWtP\nqQkive/NlR9U+7g7cDWeE5QNl4uAFyPiX6qUefu+uoh4CSjdVzeDdF9dRPwWKN1XZyNERPwr8Eq6\nKofseHqOrG271BNvAfBgml4DXJV6880EDqaqwHXAbEljUueI2SlmBdBvFZ/ZEJkP3JObv0bSVUAX\n8NXUYD0BWJ8rk28f6N1ucF65L3G1TEv7S+Du1PFqJ3A12Y/u1ZIWAi8DV6Sya4G5ZD9y3kxliYj9\nkm4g68gFcH1E7G/cLlg1TlDWcOmE8klgaQrdCtxAVvd/A9l9dZ+hcvtAuSv/ivfVASsA2tvby5ax\n5hQRm4H2MosuKlM2gMUVPqcD6Kjv1lk9OEHZcLgEeDoi9kB2X11pgaTbgIfSbLX2Ad9XZ9bi3AZl\nw+FKctV7vq/OzMrxFZQ1lKT3ALNI984l3/B9dWbWmxOUNVREvAmc1Cv26SrlfV+d2QjlKj4zMysk\nJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskjyRhZtZi2pY8\nXHHZruWXNnBLBsdXUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkgtmaCqNRCamVlzaMkEZWZmzc8JyszM\nCskJyszMCqnfBCWpQ9JeSVtzsbGSOiXtSO9jUlySbpbULWmLpOm5dRak8jskLRia3TEzs1ZRyxXU\nncCcXrElwGMRMRV4LM0DXAJMTa9FwK2QJTTgOuA8YAZwXSmpmZmZldNvgoqIJ4D9vcLzgJVpeiVw\nWS5+V2TWA6MljQcuBjojYn9EHAA66Zv0zMzM3na0bVCnRsRugPR+SopPAF7JletJsUrxPiQtktQl\nqWvfvn1HuXlmNhJIGiXpZ5IeSvNTJG1ITQn3SjouxY9P891peVvuM5am+AuSLh6ePbFy6t1JQmVi\nUSXeNxixIiLaI6J93Lhxdd04M2s5XwK25+ZvBG5KzQ8HgIUpvhA4EBEfBG5K5ZB0JjAfOIusVud7\nkkY1aNutH0eboPakqjvS+94U7wEm5cpNBF6rErcRRtIuSc9K2iypK8Xc6cYGTNJE4FLg9jQv4ELg\nvlSkd/NDqVniPuCiVH4esCoi3oqIl4BusnZyK4CjTVBrgNJJYQHwYC5+VTqxzAQOpirAdcBsSWPS\nyWd2itnI9LGImBYR7WnenW7saPwv4K+B36f5k4DXI+JQms83JbzdzJCWH0zl3fxQYLV0M78HeBI4\nQ1KPpIXAcmCWpB3ArDQPsBbYSfYr5DbgCwARsR+4AdiYXtenmBm4040NkKRPAHsjYlM+XKZo9LPM\nzQ8F1u8DCyPiygqLLipTNoDFFT6nA+gY0NZZKwrgR5IC+N8RsYJenW4k1bXTDdnVF5MnT67nftjw\nOh/4pKS5wLuAE8muqEZLOiZdJeWbEkrNDD2SjgHeT9Y72c0PBeaRJKzRzo+I6WTVd4slfbRKWf/q\ntbIiYmlETIyINrJODj+OiP8KPA5cnor1bn4oNUtcnspHis9PvfymkFUnP9Wg3bB+OEFZQ0XEa+l9\nL/AAWRuSO91YvVwLfEVSN1kb0x0pfgdwUop/hdTOGRHbgNXAc8CjwOKIONzwrbaynKCsYSS9V9IJ\npWmyzjJbcacbG4SI+ElEfCJN74yIGRHxwYi4IiLeSvHfpPkPpuU7c+svi4jTI+KMiHhkuPbD+uq3\nDcqsjk4FHsh693IM8IOIeFTSRmB16oDzMnBFKr8WmEvW6eZN4GrIOt1IKnW6AXe6MWtJTlDWMOlX\n60fKxH+JO92YWS+u4jMzs0JygjIzs0JygjIzs0JygjIzs0JygjIzs0JygjIzs0JygjIzs0JygjIz\ns0Jq6gTVtuThPvO9Y9XKm5lZcTV1ghpuTnhmZkPHCcrMzAqpZROUr27MzJpbyyYoMzNrbi2RoHy1\nZGbWeloiQZmZWetxgjIzs0IacQnK1YFmZs1hxCUoMzNrDi2ToHxlZGbWWlomQZmZWWsZ8QnKV15m\nZsU0qAQlaZekZyVtltSVYmMldUrakd7HpLgk3SypW9IWSdPrsQNmZtaa6nEF9bGImBYR7Wl+CfBY\nREwFHkvzAJcAU9NrEXBrHb67Kl8dmbUmSZMkPS5pu6Rtkr6U4gP+gSxpQSq/Q9KC4don62soqvjm\nASvT9Ergslz8rsisB0ZLGj8E398vJ67hUeWk8nVJr6Yr8c2S5ubWWZpOKi9IujgXn5Ni3ZKWlPs+\na2mHgK9GxIeBmcBiSWcywB/IksYC1wHnATOA60pJzYbfYBNUAD+StEnSohQ7NSJ2A6T3U1J8AvBK\nbt2eFDuCpEWSuiR17du374hl9U4sTlQNV+mkAnBTuhKfFhFrAdKy+cBZwBzge5JGSRoF3EJ20jkT\nuDL3OTYCRMTuiHg6Tb8BbCc7nwz0B/LFQGdE7I+IA0An2bFmBXDMINc/PyJek3QK0Cnp+SplVSYW\nfQIRK4AVAO3t7X2WW/NKP1hKP17ekFQ6qVQyD1gVEW8BL0nqJvuVC9AdETsBJK1KZZ8bso23wpLU\nBpwDbKDXD+R0boLKP5Br+uGcvmcR2dUXkydPrt8OWEWDuoKKiNfS+17gAbKTx55S1V1635uK9wCT\ncqtPBF4bzPcPhK+WiqXXSQXgmtQ20JGrYqnLSaXSFbk1P0nvA+4HvhwRv6pWtEwsqsT7BiNWRER7\nRLSPGzdu4BtrA3bUCUrSeyWdUJoGZgNbgTVAqaFxAfBgml4DXJUaK2cCB0u/dGxkKXNSuRU4HZhG\ndoX1rVLRMqv7pGIASDqW7Di6OyJ+mMID/YE8rD+crbrBXEGdCvxU0jPAU8DDEfEosByYJWkHMCvN\nA6wFdgLdwG3AFwbx3dakyp1UImJPRByOiN+THRulajyfVKwsSQLuALZHxLdziwb6A3kdMFvSmHTl\nPjvFrACOug0q1f9/pEz8l8BFZeIBLD7a77PmV+mkIml87mr6U2RX4pCdVH4g6dvAB8h6YD1FdgU1\nVdIU4FWyjhR/3pi9sII4H/g08KykzSn2N2Q/iFdLWgi8DFyRlq0F5pL9QH4TuBogIvZLugHYmMpd\nHxH7G7ML1p/BdpIwG4hKJ5UrJU0jq6bbBXwWICK2SVpN1vnhELA4Ig4DSLqG7JfuKKAjIrY1ckds\neEXETylf1QsD/IEcER1AR/22zurFCcoapspJZW2VdZYBy8rE11Zbz8ya34gfi8/MzIrJCcrMzArJ\nCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCQqPdG5mVkROUGZmVkgjNkH5qsnM\nrNiaMkENJLkMNBE5cZmZFUNTJqih4uRkZlYcTlBmZlZITlBmZlZITlBJueq9UsxVf2ZmjecEVUG1\nhGVmZkPPCcrMzArJCcrMzArJCcrMzArJCcrMzArJCaofvXvytS152J0lzMwa4Jjh3oAiqiUBOUmZ\n2UhT7byMt/7iAAAERklEQVS3a/mldf8+X0GZmVkhNTxBSZoj6QVJ3ZKWNPr7rXX4WLJ68bFUTA2t\n4pM0CrgFmAX0ABslrYmI5xq5HfXUtuThIbm0tepa8Viy4THSjqX+mieKdD5rdBvUDKA7InYCSFoF\nzAOa+kCopT0q/49eKl+kA6EJteSxZMPCx1IdDEX7VKMT1ATgldx8D3BevoCkRcCiNPtrSS+k6ZOB\nXwz5Fg4R3VhbrA56/53+aEi+Zfj1eyzB0R9PQ/Rv01R0o4+lvKE4Nw3mOBuqY7TGzx3QPpf5zJqO\npUYnKJWJxREzESuAFX1WlLoion2oNqxVjKC/U7/HEvh4GowR9DfysTRAjdrnRneS6AEm5eYnAq81\neBusNfhYsnrxsVRQjU5QG4GpkqZIOg6YD6xp8DZYa/CxZPXiY6mgGlrFFxGHJF0DrANGAR0Rsa3G\n1ftcWltZI+LvNMhjCUbI32mQRsTfyMfSUWnIPiuiT1WrmZnZsPNIEmZmVkhOUGZmVkhNkaBadRgS\nSR2S9kramouNldQpaUd6H5PiknRz+htskTQ9t86CVH6HpAW5+LmSnk3r3CxJR/sdraLc39yOJGmS\npMclbZe0TdKXhnubiqpVz03VSNqVziubJXUN6ZdFRKFfZI2WLwKnAccBzwBnDvd21WnfPgpMB7bm\nYt8AlqTpJcCNaXou8AjZPRszgQ0pPhbYmd7HpOkxadlTwJ+mdR4BLjma72ilV7m/uV99/kbjgelp\n+gTg563yf67Of6eWPTf1s9+7gJMb8V3NcAX19jAkEfFboDQMSdOLiCeA/b3C84CVaXolcFkufldk\n1gOjJY0HLgY6I2J/RBwAOoE5admJEfFkZEfVXb0+ayDf0TIq/M0tJyJ2R8TTafoNYDvZaAt2pJY9\nNxVFMySocsOQtPJ/llMjYjdkJwrglBSv9HeoFu8pEz+a77ARSlIbcA6wYXi3pJBG6v+XAH4kaVMa\n/mnINMMDC2sahmQEqPR3GGj8aL7DRiBJ7wPuB74cEb8a7u0poJH6/+X8iHhN0ilAp6TnU81E3TXD\nFdRIG4ZkT6laLb3vTfFKf4dq8Yll4kfzHTbCSDqWLDndHRE/HO7tKagR+f8lIl5L73uBB8iqOodE\nMySokTYMyRqg1BNvAfBgLn5V6mk3EziYqufWAbMljUm98WYD69KyNyTNTL33rur1WQP5DhtB0vFy\nB7A9Ir493NtTYCPt3ISk90o6oTRNdr4Zuh6xw90jpMZeI3PJehK9CHxtuLenjvt1D7Ab+B3Zr7GF\nwEnAY8CO9D42lRXZQ9VeBJ4F2nOf8xmgO72uzsXb08HzIvBd3hk5ZMDf0Sqvcn/z4d6mor2A/0BW\nVbUF2Jxec4d7u4r4atVzU5X9PY2st+IzwLah3mcPdWRmZoXUDFV8ZmY2AjlBmZlZITlBmZlZITlB\nmZlZITlBmZlZITlBmZlZITlBmZlZIf1/bGlS+GuZvxcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dd0518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We should always start by plotting the distribution of our examples\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "ax[0].hist(X[:, 0], bins=100)  # PLot given credit\n",
    "ax[1].hist(X[:, 1])           # Gender\n",
    "ax[2].hist(X[:, 2])           # Education\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noiiK4pFUgFIURVE80v8Hd3KO67WfawYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14853470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some variables in our dataset have a temporal aspect, \n",
    "# that we can visualize for a few selected clients\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "ax[0].plot(X[0:4, 5:10])  # PLot past payments status\n",
    "ax[0].grid()\n",
    "ax[1].plot(X[0:4, 11:16]) # Plot bill statements\n",
    "ax[1].grid()\n",
    "ax[2].plot(X[0:4, 17:23]) # Plot amount of previous payments\n",
    "ax[2].grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A little bit of terminology:\n",
    "<ol>\n",
    "<li>The matrices (X, y) are called the <strong>dataset</strong> for our problem.</li>\n",
    "<li>One row of (X, y) is called an <strong>example</strong>.</li>\n",
    "<li>Each item in X is a <strong>feature</strong>: a single element characterizing an example.</li>\n",
    "<li>Each item in y is called a <strong>label</strong>, characterizing the class to which an example belongs to.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our task: learn to categorize elements described by the same features, which <strong>we do not yet know</strong>!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### sklearn interface\n",
    "<p>The interface of sklearn is composed of a few generic functions, working in the same way for all possible objects:</p>\n",
    "<ul>\n",
    "<li><strong>fit</strong>: adapt the object based on some training data.</li>\n",
    "<li><strong>transform</strong>: apply the trained object on new data (can also use <strong>predict</strong> for supervised models).</li>\n",
    "<li><strong>score</strong>: apply a predefined scoring function to evaluate the model.\n",
    "</ul>\n",
    "<p>Any parameter is provided in the constructor of the object, in most cases via name/value pairs. In this way, the interface of the base functions is extremely compact.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 1 in preprocessing: missing values\n",
    "A common problem during preprocessing is handling missing values. A simple strategy is to replace them with the average (or median) over the corresponding column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.40000e+05 2.00000e+00 2.00000e+00 2.00000e+00 3.40000e+01 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 2.23815e+04\n",
      " 2.12000e+04 2.00885e+04 1.90520e+04 1.81045e+04 1.70710e+04 2.10000e+03\n",
      " 2.00900e+03 1.80000e+03 1.50000e+03 1.50000e+03 1.50000e+03]\n"
     ]
    }
   ],
   "source": [
    "# We do this for \"NaN\"\n",
    "from sklearn import preprocessing\n",
    "inputer = preprocessing.Imputer(strategy=\"median\", verbose=2)\n",
    "X = inputer.fit_transform(X)\n",
    "print(inputer.statistics_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2 in preprocessing: categorical variables\n",
    "<p>Consider column 3 (marital status). The distance between \"married\" and \"single\" is 1, but the distance between \"others\" and \"single\" is 2!</p>\n",
    "<br />\n",
    "<div class=\"alert alert-warning\">\n",
    "<p>We are imposing a <em>metric space</em> on categorical data, which is generally confusing for learning algorithms.</p>\n",
    "</div>\n",
    "\n",
    "<p>Now consider the transformation single $= [1, 0, 0]$, married $ = [0, 1, 0]$ and others $ = [0, 0 ,1]$. Now all pairwise distances are either $0$ or $\\sqrt{2}$. This is called <strong>one-hot encoding</strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.396267</td>\n",
       "      <td>0.603733</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.352833</td>\n",
       "      <td>0.467667</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>...</td>\n",
       "      <td>4.701315e+04</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.021598</td>\n",
       "      <td>0.477859</td>\n",
       "      <td>0.498962</td>\n",
       "      <td>0.370191</td>\n",
       "      <td>0.063901</td>\n",
       "      <td>0.096159</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.042389</td>\n",
       "      <td>...</td>\n",
       "      <td>6.934939e+04</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.572640e+05</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666250e+03</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.008850e+04</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.016475e+04</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.664089e+06</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.396267      0.603733      0.000467      0.352833      0.467667   \n",
       "std        0.489129      0.489129      0.021598      0.477859      0.498962   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      0.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.163900      0.004100      0.009333      0.001700      0.001800   \n",
       "std        0.370191      0.063901      0.096159      0.041197      0.042389   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...                  23             24             25  \\\n",
       "count      ...        3.000000e+04   30000.000000   30000.000000   \n",
       "mean       ...        4.701315e+04   43262.948967   40311.400967   \n",
       "std        ...        6.934939e+04   64332.856134   60797.155770   \n",
       "min        ...       -1.572640e+05 -170000.000000  -81334.000000   \n",
       "25%        ...        2.666250e+03    2326.750000    1763.000000   \n",
       "50%        ...        2.008850e+04   19052.000000   18104.500000   \n",
       "75%        ...        6.016475e+04   54506.000000   50190.500000   \n",
       "max        ...        1.664089e+06  891586.000000  927171.000000   \n",
       "\n",
       "                  26             27            28            29  \\\n",
       "count   30000.000000   30000.000000  3.000000e+04   30000.00000   \n",
       "mean    38871.760400    5663.580500  5.921163e+03    5225.68150   \n",
       "std     59554.107537   16563.280354  2.304087e+04   17606.96147   \n",
       "min   -339603.000000       0.000000  0.000000e+00       0.00000   \n",
       "25%      1256.000000    1000.000000  8.330000e+02     390.00000   \n",
       "50%     17071.000000    2100.000000  2.009000e+03    1800.00000   \n",
       "75%     49198.250000    5006.000000  5.000000e+03    4505.00000   \n",
       "max    961664.000000  873552.000000  1.684259e+06  896040.00000   \n",
       "\n",
       "                  30             31             32  \n",
       "count   30000.000000   30000.000000   30000.000000  \n",
       "mean     4826.076867    4799.387633    5215.502567  \n",
       "std     15666.159744   15278.305679   17777.465775  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%       296.000000     252.500000     117.750000  \n",
       "50%      1500.000000    1500.000000    1500.000000  \n",
       "75%      4013.250000    4031.500000    4000.000000  \n",
       "max    621000.000000  426529.000000  528666.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_pre = preprocessing.OneHotEncoder(categorical_features = (1,2,3), sparse=False).fit_transform(X)\n",
    "pd.DataFrame(X_pre).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>Our features have very different scales, e.g. [0,1] for the categorical features, and [0, 528666] for the last column (amount of previous payments in April 2005). Let us consider a prototypical male user with last column = 10000.</p>\n",
    "\n",
    "<ul>\n",
    "<li>Switching the sex from male to female: distance from old pattern is $\\sqrt{2}$.</li>\n",
    "<li>A $1\\%$ change in the last column: distance from old pattern is now $\\sqrt{500}$!</li>\n",
    "</ul>\n",
    "\n",
    "<p>The process of making all features similar is called <strong>feature normalization</strong>. Consider a generic value $X_{i,j}$ of the input matrix, and denote by $X_{\\text{min}}$ and $X_{\\text{max}}$ the minimum and maximum values computed over the corresponding column. Classical feature scaling in [0,1] is obtained as:</p>\n",
    "\n",
    "\\begin{equation}\n",
    "X_{i,j} = \\frac{X_{i,j} - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.396267</td>\n",
       "      <td>0.603733</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.352833</td>\n",
       "      <td>0.467667</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112157</td>\n",
       "      <td>0.200891</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>0.290851</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.009865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.021598</td>\n",
       "      <td>0.477859</td>\n",
       "      <td>0.498962</td>\n",
       "      <td>0.370191</td>\n",
       "      <td>0.063901</td>\n",
       "      <td>0.096159</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.042389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.045766</td>\n",
       "      <td>0.018961</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.025227</td>\n",
       "      <td>0.035820</td>\n",
       "      <td>0.033627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087808</td>\n",
       "      <td>0.162330</td>\n",
       "      <td>0.082396</td>\n",
       "      <td>0.261944</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097374</td>\n",
       "      <td>0.178084</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.274097</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.002837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119378</td>\n",
       "      <td>0.211482</td>\n",
       "      <td>0.130415</td>\n",
       "      <td>0.298787</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.007566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.396267      0.603733      0.000467      0.352833      0.467667   \n",
       "std        0.489129      0.489129      0.021598      0.477859      0.498962   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      0.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.163900      0.004100      0.009333      0.001700      0.001800   \n",
       "std        0.370191      0.063901      0.096159      0.041197      0.042389   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...                 23            24            25            26  \\\n",
       "count      ...       30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       ...           0.112157      0.200891      0.120620      0.290851   \n",
       "std        ...           0.038076      0.060601      0.060284      0.045766   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.087808      0.162330      0.082396      0.261944   \n",
       "50%        ...           0.097374      0.178084      0.098600      0.274097   \n",
       "75%        ...           0.119378      0.211482      0.130415      0.298787   \n",
       "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 27            28            29            30            31  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.006483      0.003516      0.005832      0.007771      0.011252   \n",
       "std        0.018961      0.013680      0.019650      0.025227      0.035820   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.001145      0.000495      0.000435      0.000477      0.000592   \n",
       "50%        0.002404      0.001193      0.002009      0.002415      0.003517   \n",
       "75%        0.005731      0.002969      0.005028      0.006463      0.009452   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 32  \n",
       "count  30000.000000  \n",
       "mean       0.009865  \n",
       "std        0.033627  \n",
       "min        0.000000  \n",
       "25%        0.000223  \n",
       "50%        0.002837  \n",
       "75%        0.007566  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_norm = scaler.fit_transform(X_pre)\n",
    "pd.DataFrame(X_norm).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another way of normalizing is <strong>standard scaling</strong>. Given the estimated mean $\\mu$ and variance $\\sigma^2$ for a column we process the values as:\n",
    "\n",
    "\\begin{equation}\n",
    "X_{i,j} = \\frac{X_{i,j} - \\mu}{\\sigma^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>A third type of scaling implemented in scikit-learn is a robust scaling (mostly to outliers), where we substract the mean and scale according to a given range:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.396267</td>\n",
       "      <td>-0.396267</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.352833</td>\n",
       "      <td>0.467667</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468267</td>\n",
       "      <td>0.463996</td>\n",
       "      <td>0.458560</td>\n",
       "      <td>0.454730</td>\n",
       "      <td>0.889561</td>\n",
       "      <td>0.938844</td>\n",
       "      <td>0.832486</td>\n",
       "      <td>0.894768</td>\n",
       "      <td>0.873085</td>\n",
       "      <td>0.957049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.021598</td>\n",
       "      <td>0.477859</td>\n",
       "      <td>0.498962</td>\n",
       "      <td>0.370191</td>\n",
       "      <td>0.063901</td>\n",
       "      <td>0.096159</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.042389</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206108</td>\n",
       "      <td>1.232920</td>\n",
       "      <td>1.255426</td>\n",
       "      <td>1.242205</td>\n",
       "      <td>4.134618</td>\n",
       "      <td>5.529367</td>\n",
       "      <td>4.278727</td>\n",
       "      <td>4.214449</td>\n",
       "      <td>4.042949</td>\n",
       "      <td>4.579166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.084472</td>\n",
       "      <td>-3.623126</td>\n",
       "      <td>-2.053348</td>\n",
       "      <td>-7.439659</td>\n",
       "      <td>-0.524214</td>\n",
       "      <td>-0.482121</td>\n",
       "      <td>-0.437424</td>\n",
       "      <td>-0.403524</td>\n",
       "      <td>-0.396930</td>\n",
       "      <td>-0.386374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303004</td>\n",
       "      <td>-0.320535</td>\n",
       "      <td>-0.337443</td>\n",
       "      <td>-0.329876</td>\n",
       "      <td>-0.274588</td>\n",
       "      <td>-0.282217</td>\n",
       "      <td>-0.342649</td>\n",
       "      <td>-0.323895</td>\n",
       "      <td>-0.330114</td>\n",
       "      <td>-0.356044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696996</td>\n",
       "      <td>0.679465</td>\n",
       "      <td>0.662557</td>\n",
       "      <td>0.670124</td>\n",
       "      <td>0.725412</td>\n",
       "      <td>0.717783</td>\n",
       "      <td>0.657351</td>\n",
       "      <td>0.676105</td>\n",
       "      <td>0.669886</td>\n",
       "      <td>0.643956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.592059</td>\n",
       "      <td>16.721858</td>\n",
       "      <td>18.771700</td>\n",
       "      <td>19.702726</td>\n",
       "      <td>217.536695</td>\n",
       "      <td>403.707703</td>\n",
       "      <td>217.312272</td>\n",
       "      <td>166.655458</td>\n",
       "      <td>112.471289</td>\n",
       "      <td>135.788782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.396267     -0.396267      0.000467      0.352833      0.467667   \n",
       "std        0.489129      0.489129      0.021598      0.477859      0.498962   \n",
       "min        0.000000     -1.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000     -1.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "max        1.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.163900      0.004100      0.009333      0.001700      0.001800   \n",
       "std        0.370191      0.063901      0.096159      0.041197      0.042389   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...                 23            24            25            26  \\\n",
       "count      ...       30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       ...           0.468267      0.463996      0.458560      0.454730   \n",
       "std        ...           1.206108      1.232920      1.255426      1.242205   \n",
       "min        ...          -3.084472     -3.623126     -2.053348     -7.439659   \n",
       "25%        ...          -0.303004     -0.320535     -0.337443     -0.329876   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.696996      0.679465      0.662557      0.670124   \n",
       "max        ...          28.592059     16.721858     18.771700     19.702726   \n",
       "\n",
       "                 27            28            29            30            31  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.889561      0.938844      0.832486      0.894768      0.873085   \n",
       "std        4.134618      5.529367      4.278727      4.214449      4.042949   \n",
       "min       -0.524214     -0.482121     -0.437424     -0.403524     -0.396930   \n",
       "25%       -0.274588     -0.282217     -0.342649     -0.323895     -0.330114   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.725412      0.717783      0.657351      0.676105      0.669886   \n",
       "max      217.536695    403.707703    217.312272    166.655458    112.471289   \n",
       "\n",
       "                 32  \n",
       "count  30000.000000  \n",
       "mean       0.957049  \n",
       "std        4.579166  \n",
       "min       -0.386374  \n",
       "25%       -0.356044  \n",
       "50%        0.000000  \n",
       "75%        0.643956  \n",
       "max      135.788782  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "scaler = sklearn.preprocessing.RobustScaler() # Default to the interquantile range\n",
    "#scaler = sklearn.preprocessing.RobustScaler(quantile_range=(0.01, 0.99)) # Select a custom range\n",
    "X_norm = scaler.fit_transform(X_pre) \n",
    "# X_norm = scaler.\n",
    "pd.DataFrame(X_norm).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2 - Model training and fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider a model that predicts the true class for the elements in the training set, 0 otherwise. This has excellent <strong>training performance</strong>, but it doesn't <strong>generalize</strong>.\n",
    "\n",
    "This is called <strong>overfitting</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In order to detect overfitting, we can keep a small percentage of the data for test purposes (<strong>holdout</strong> method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 22500 elements for training and 7500 for test.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "X_norm = preprocessing.MinMaxScaler().fit_transform(X_pre)\n",
    "(X_trn, X_tst, y_trn, y_tst) = model_selection.train_test_split(X_norm, y, test_size=0.25)\n",
    "print('We now have', \n",
    "      X_trn.shape[0], 'elements for training and', X_tst.shape[0], 'for test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us look at the proportions of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.92 % / 22.720000000000002 %\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_trn)*100, '% /', np.mean(y_tst)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>The distribution is not perfectly equivalent between the two sets. We can do better with a <strong>stratified</strong> holdout:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.12 % / 22.12 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "(X_trn, X_tst, y_trn, y_tst) = model_selection.train_test_split(X_norm, y, test_size=0.25, stratify=y)\n",
    "print(np.mean(y_trn)*100, '% /', np.mean(y_tst)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>We need a <strong>baseline</strong> accuracy to start our investigation. The <code>DummyClassifier</code> will output <em>constant</em> predictions with the most frequent item in the training set (note that we need to encode also the output using a one-hot-encoding for the method to work):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7788"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trn_dummy = preprocessing.OneHotEncoder(sparse=False).fit_transform(y_trn).astype(int)\n",
    "y_tst_dummy = preprocessing.OneHotEncoder(sparse=False).fit_transform(y_tst).astype(int)\n",
    "\n",
    "from sklearn import dummy\n",
    "d = dummy.DummyClassifier(strategy='most_frequent').fit(X_trn, y_trn_dummy)\n",
    "d.score(X_tst, y_tst_dummy) # Returns binary classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<p>An accuracy is always \"good\" compared to some alternative. Any model performing with an accuracy lower than $77.88\\%$ is basically useless in this scenario. At the same time, maybe even a $1\\%$ improvement is very significant here!</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How do we choose a proper classifier now?</h2></center>\n",
    "<center><img src=\"./Images/ml_map.png\"  /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic regression\n",
    "Let us start with the simplest one! A linear model is defined as:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = \\mathbf{w}^T\\mathbf{x} + b\n",
    "$$\n",
    "\n",
    "The vector $\\mathbf{w}$ and scalar $b$ are called <strong>parameters</strong> of the model, and should be chosen based on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With a linear model, the output can be boundless, while we prefer to have a probability that the input belongs to a given class. We can achieve this using a nonlinear transformation:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = \\frac{1}{1+\\exp\\left\\{-\\mathbf{w}^T\\mathbf{x}-b\\right\\}}\n",
    "$$\n",
    "\n",
    "The nonlinear transformation ensures that the output is a correct probability in [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14e05630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_range = np.arange(-5.0, 5.0, 0.01)\n",
    "plt.plot(x_range, 1/(1+np.exp(x_range)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finding the optimal parameters is done by minimizing some <strong>error</strong> (<strong>loss</strong>) on our dataset. In the case of logistic regression, it is cross-entropy:\n",
    "\n",
    "$$\n",
    "J(w, b) = - \\sum_{i=1}^N y_i \\log\\left\\{f(x_i)\\right\\} + (1-y_i)\\log\\left\\{1 - f(x_i)\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Understanding cross-entropy\n",
    "<br /><br />\n",
    "<center><img src=\"./Images/CrossEntropyDef.png\"  /></center>\n",
    "\n",
    "http://colah.github.io/posts/2015-09-Visual-Information/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X_trn, y_trn)\n",
    "print(logreg.score(X_tst, y_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Play around with the regularization factor C!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This <strong>regularization factor</strong> expresses a preference for solutions with small weights. It is another way to prevent overfitting.\n",
    "\n",
    "However, this parameter needs to be chosen by the user: in statistical terminology, it is called an <strong>hyper-parameter</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>How do we choose a proper regularization factor $C$? We can do the same as for testing:</p>\n",
    "\n",
    "<ol>\n",
    "<li>Split our training data in two, and use one part for training and one part for evaluating performance.</li>\n",
    "<li>Train and evaluate several models with different parameters.</li>\n",
    "<li>Select the parameter giving rise to the highest accuracy, retrain the final model with that parameter and the full training set.</li>\n",
    "</ol>\n",
    "\n",
    "<p>This is called <strong>grid search</strong>. A better way to evaluate the classifier is $k$-fold cross-validation (next), which can be used also for testing. We now have:</p>\n",
    "\n",
    "<ul>\n",
    "<li><strong>Training set</strong> used for training.</li>\n",
    "<li><strong>Validation set </strong> used for selecting <em>hyper-parameters</em> (like $C$).</li>\n",
    "<li><strong>Test set</strong> to evaluate the final performance.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./Images/07_cross_validation_diagram.png\" />\n",
    "<a href=\"http://blog.kaggle.com/2015/06/29/scikit-learn-video-7-optimizing-your-model-with-cross-validation/\">Image source</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./Images/nested-k-fold.png\" />\n",
    "<a href=\"http://sebastianraschka.com/faq/docs/evaluate-a-model.html\">Image source</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For parameters like $C$, it makes more sense to search them in an exponential range, like:\n",
    "\n",
    "$$\n",
    "2^{-10}, \\ldots, 2^{-9}, \\ldots, 2^{9}, 2^{10} \\,.\n",
    "$$\n",
    "\n",
    "<p>This is because a small change (e.g., $105$ instead of $100$) might not influence the result if we are not close to the optimal point, and a very fine-grained research is too time consuming.</p>\n",
    "\n",
    "Eventually, a second fine-tuning can be made around the optimal coefficient:\n",
    "<pre>Hsu, C.W., Chang, C.C. and Lin, C.J., 2003. A practical guide to support vector classification.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Note that in logistic regression for sklearn, C is the inverse of the regularization strength.\n",
    "\n",
    "# The dictionary has the parameters we want to test, and their respective values\n",
    "d = {'C': 2.0**np.arange(-10, 10, 1)}\n",
    "\n",
    "# A grid-search is defined with a model and the dictionary of parameters\n",
    "logreg_cv = sklearn.model_selection.GridSearchCV(logreg, d, verbose=1) # Default is a 3-fold cross-validation\n",
    "\n",
    "# We can fit it equivalently to a standard model\n",
    "logreg_cv.fit(X_trn, y_trn)\n",
    "print('Accuracy: ', logreg_cv.score(X_tst, y_tst)*100, ' %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Very small C: regularization is too large, all coefficients become 0\n",
    "# Very large C: the accuracy reaches a plateau, there appear to be no overfitting in this case\n",
    "\n",
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.plot(d['C'], logreg_cv.cv_results_['mean_test_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Cross-validated accuracy')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also plot the resulting best parameter found by the grid-search procedure\n",
    "print(logreg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final bits of theory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you solve the optimization problem? The simplest idea is to use <strong>gradient descent</strong>, an iterative procedure:\n",
    "\n",
    "$$\n",
    "w = w - \\alpha \\nabla J(w)\n",
    "$$\n",
    "\n",
    "(sklearn solves the problem with a more advanced optimization technique, but GD is the basis for most optimization in more complex models, such as deep learning models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stochastic optimization\n",
    "\n",
    "For very big datasets, we cannot compute the gradient for the entire dataset. In this case, we can compute each step with a small sample of the entire training dataset.\n",
    "\n",
    "This is called <strong>stochastic</strong> gradient descent (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sgd = linear_model.SGDClassifier(loss='hinge', penalty='l2', n_iter=100)  # This is a linear SVM\n",
    "sgd.fit(X_trn, y_trn).score(X_tst, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sgd = linear_model.SGDClassifier(loss='huber', penalty='l2', n_iter=100)  # Robust regression\n",
    "sgd.fit(X_trn, y_trn).score(X_tst, y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The steps up to now\n",
    "Let us summarize the main steps of a supervised learning workflow up to now:\n",
    "<ol>\n",
    "<li>Problem definition and data collection.</li>\n",
    "<li><strong>Data preprocessing</strong>: at least data normalization, one-hot-encoding when needed, and missing data removal / imputation. Later on, we will add feature selection, feature transformation, and column normalization.</li>\n",
    "<li><strong>Model selection</strong>: there are many families of classifiers, a brief overview is given next.</li>\n",
    "<li><strong>Data splitting, model training, and model fine-tuning</strong>.</li>\n",
    "<li><strong>Model evaluation</strong> (more later on), and final deploy.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>In machine learning, there are hundreds of possible classifiers, organized in different \"families\" of methods, each with their own strengths and weaknesses in terms of several factors, e.g.:</p>\n",
    "\n",
    "<pre>FernÃ¡ndez-Delgado, M., Cernadas, E., Barro, S. and Amorim, D., 2014. Do we need hundreds of classifiers to solve real world classification problems?. J. Mach. Learn. Res, 15(1), pp. 3133-3181.</pre>\n",
    "\n",
    "<p>We will briefly review some of the most important implemented in scikit-learn. Remember that, in many cases, the actual bottleneck can be another, e.g. availability of data, feature extraction, and so on.</p>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<a href=\"http://scikit-learn.org/stable/modules/classes.html\">Read more on each family in the user guides of scikit-learn!</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing a model: the trade-offs\n",
    "<p>Accuracy is not the only element to consider when choosing the 'correct' classification model. Each algorithm provides a different trade-off along a multidimensional set of parameters, among which:</p>\n",
    "<ol>\n",
    "<li><strong>Complexity</strong>: some algorithms can model highly nonlinear functions, while others (e.g., linear) are much simpler.</li>\n",
    "<li><strong>Speed of learning</strong> and <strong>speed of classification</strong>.</li>\n",
    "<li><strong>Robustness</strong> to irrelevant attributes, missing values, noise.</li>\n",
    "<li><strong>Transparency</strong> of the decisions.</li>\n",
    "<li>...</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./Images/Classifiers_comparison.png\"  /></center>\n",
    "<p>Taken from: Kotsiantis, S.B., 2007. <strong>Supervised machine learning: a review of classification techniques</strong>. <em>Informatica</em>, 31(3), pp.249-269.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### k-Nearest Neighbors\n",
    "<p>The KNN simply predicts a class according to the most similar items in the training set.</p>\n",
    "\n",
    "<font color=\"green\">Pros</font>\n",
    "<ol>\n",
    "<li>No training required.</li>\n",
    "<li>Can be re-implemented immediately.</li>\n",
    "<li>Highly nonlinear decision function.</li>\n",
    "</ol>\n",
    "\n",
    "<font color=\"red\">Cons</font>\n",
    "<ol>\n",
    "<li>Needs to store the entire training dataset.</li>\n",
    "<li>Performs poorly with many features, due to the curse of dimensionality.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./Images/KnnClassification.svg.png\" />\n",
    "<a href=\"https://commons.wikimedia.org/wiki/File:KnnClassification.svg \">Image source</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./Images/Curse_of_dimensionality.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISPAMM\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  79.17333333333333  %.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier().fit(X_trn, y_trn)\n",
    "print('Accuracy: ', knn.score(X_tst, y_tst)*100, ' %.') # Most of the time is now spent in evaluating the classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Support vector machine\n",
    "<strong>Support vector machines</strong> (SVMs) builds a linear classifier on a new space $\\phi(\\boldsymbol{x})$ defined <em>implicitly</em> by a kernel function:\n",
    "\n",
    "\\begin{equation}\n",
    "k(\\boldsymbol{x}_1, \\boldsymbol{x}_2) = \\phi(\\boldsymbol{x}_1)^T\\phi(\\boldsymbol{x}_2)\n",
    "\\end{equation}\n",
    "\n",
    "<font color=\"green\">Pros</font>\n",
    "<ol>\n",
    "<li>State-of-the-art accuracy for medium datasets.</li>\n",
    "<li>Provable convergence guarantees and many theoretical analyses.</li>\n",
    "<li>Can use kernels defined on many objects (e.g., graphs).</li>\n",
    "<li>Random approximations for use in large-scale datasets.</li>\n",
    "</ol>\n",
    "\n",
    "<font color=\"red\">Cons</font>\n",
    "<ol>\n",
    "<li>No immediate interpretation.</li>\n",
    "<li>For most non-linear kernels, we need to select additional hyper-parameters.</li>\n",
    "<li>Storage requirements linear (approximately) with the size of the training set.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISPAMM\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  80.92  %.\n"
     ]
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "svm = sklearn.svm.SVC(kernel='rbf', gamma=1)\n",
    "svm.fit(X_trn, y_trn)\n",
    "print('Accuracy: ', svm.score(X_tst, y_tst)*100, ' %.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision Trees\n",
    "\n",
    "A decision tree represents the relation as a directed tree in which at every node we test the value of a feature for selecting the branch to follow.\n",
    "\n",
    "<font color=\"green\">Pro</font>\n",
    "<ol>\n",
    "<li>Can be interpreted by the user.</li>\n",
    "<li>Can associate an 'importance' to each feature.</li>\n",
    "</ol>\n",
    "\n",
    "<font color=\"red\">Cons</font>\n",
    "<ol>\n",
    "<li>Accuracy might not be optimal.</li>\n",
    "<li>The construction process is heavily heuristic.</li>\n",
    "<li>Lots of variance.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./Images/tvTree.jpg\" />\n",
    "<a href=\"http://www.sfs.uni-tuebingen.de/~vhenrich/ss12/java/homework/hw7/decisionTrees.html\">Image source</a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "dec_tree = sklearn.tree.DecisionTreeClassifier(max_depth=5, max_features=5)\n",
    "dec_tree.fit(X_trn, y_trn)\n",
    "print('Accuracy: ', dec_tree.score(X_tst, y_tst)*100, ' %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(dec_tree.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural Networks\n",
    "\n",
    "Neural networks can model highly nonlinear functions, and they are at the heart of \"deep learning\".\n",
    "\n",
    "<font color=\"green\">Pro</font>\n",
    "<ol>\n",
    "<li>For high-dimensional data (with enough examples), accuracies are state-of-the-art.</li>\n",
    "<li>Lot of hype recently, with many dedicated libraries.</li>\n",
    "</ol>\n",
    "\n",
    "<font color=\"red\">Cons</font>\n",
    "<ol>\n",
    "<li>Many hyper-parameters to tune for large networks.</li>\n",
    "<li>Nonconvex training problem with many minima and saddle points.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./Images/tikz11.png\" />\n",
    "<a href=\"http://neuralnetworksanddeeplearning.com/chap1.html\">Image source</a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISPAMM\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  81.09333333333333  %.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x15b6a358>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nixKJiIiMixKJiIiMixKJiIiMy/8HyJkJJHGK1tUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x158ac3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.neural_network\n",
    "nnet = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(20), solver='adam', max_iter=500, batch_size=100)\n",
    "nnet.fit(X_trn, y_trn)\n",
    "print('Accuracy: ', nnet.score(X_tst, y_tst)*100, ' %.')\n",
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.plot(nnet.loss_curve_)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A curiosity: auto machine learning\n",
    "<p>Recently, there is interest in designing <strong>automatic systems</strong> for supervised learning. One example is the <a href=\"http://automl.org/\" target=\"_blank\">AutoML package</a>, which is a wrapper around scikit-learn.</p>\n",
    "\n",
    "<center><img src=\"./Images/AutoML_architecture.png\" />\n",
    "<p>An overview of the AutoML system taken from: Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M. and Hutter, F., 2015. <strong>Efficient and robust automated machine learning</strong>. In <em>Advances in Neural Information Processing Systems</em> (pp. 2962-2970).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Can only run on Ubuntu for now! :-(\n",
    "\n",
    "import autosklearn.classification\n",
    "\n",
    "automl = autosklearn.classification.AutoSklearnClassifier()\n",
    "automl.fit(X_trn, y_trn)\n",
    "y_hat = automl.predict(X_tst)\n",
    "\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_tst, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unbalanced learning\n",
    "<p>The dataset we have been using has a strong imbalance between positive and negative examples. One way to correct this is to resample the dataset to obtain balanced classes. Another is to give more weight to the smaller class:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_weights = svm.LinearSVC(class_weight='balanced')\n",
    "clf_weights.fit(X_trn, y_trn, sample_weight=y_trn).score(X_tst, y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is an entire scikit-learn contributed module for unbalanced learning: [scikit-learn-contrib/imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>In unbalanced learning, it is especially import to consider metrics more advanced than the simple average accuracy:</p>\n",
    "<ol>\n",
    "<li><strong>Precision</strong>: percentage of positive predictions which are correct.</li>\n",
    "<li><strong>Recall</strong>: percentage of positives correctly predicted by the algorithm.</li>\n",
    "<li><strong>F1-score</strong>: harmonic mean of the two.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_tst, logreg.predict(X_tst)))\n",
    "print('Confusion matrix:\\n-----------------\\n', metrics.confusion_matrix(y_tst, logreg.predict(X_tst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plotting precision and recall for different roundings of the classifier predictions gives us the precision-recall curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision, recall, _ = metrics.precision_recall_curve(y_tst, logreg.decision_function(X_tst))\n",
    "plt.plot(recall, precision, color='navy',\n",
    "         label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advanced profiling\n",
    "<p>When computational considerations are especially important, we can use an advanced profiler for our code, such as <a href=\"https://jiffyclub.github.io/snakeviz/\">SnakeViz</a>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext snakeviz\n",
    "% snakeviz linear_model.RidgeClassifier().fit(X_trn, y_trn)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
